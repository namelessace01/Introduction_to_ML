{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1d177-e912-482f-ac99-7485df8d213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93a61d-544e-4cc7-8051-d4f120db936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset to a variable\n",
    "melb_data = pd.read_csv(\"melb_data.csv\")\n",
    "# Reading the first five rows of the dataset\n",
    "melb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2081b-1fbc-4e20-9185-17f392a8933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_data.describe().transpose()\n",
    "# Discovered that: \"count\" - shows how many rows have non-missing values\n",
    "# \"mean\" - is the average of the numerical data\n",
    "# \"std\" - is the standard deviation of the numerical data\n",
    "# min, 25%, 50%, 75%, max are the levels of percentile and the minimum and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae2da6-581c-4126-acdc-972f924f9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To views all columns in a dataset\n",
    "melb_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bb9d4-b2a7-447b-9ec5-e97dc09f13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melb_data_new = melb_data.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a562b-15e2-4f1c-b0af-03c1aca3b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_data_new.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac62f8d1-e73c-49ad-8883-e3199df14a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pull out a variable with dot-notation\n",
    "# The value of y is what we call the \"Prediction Target\" and we use dot-notation to select the column for that\n",
    "y = melb_data_new.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7831a-aa6c-43bf-9a6e-009d8ffb770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating independent features for y\n",
    "melb_features = [\"Rooms\", \"Bathroom\", \"Landsize\", \"Lattitude\", \"Longtitude\"]\n",
    "X = melb_data_new[melb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f633f76-9abd-4005-a6e1-234b96fd7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a23e8-e346-4c3d-9e04-ba6fa38e93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4482f06-543f-4e92-82c6-869b11804ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5b466-79fe-46fe-923a-140a3f745c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_model = DecisionTreeRegressor(random_state=1)\n",
    "melb_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4cce8-e32f-498f-9589-dc1c1aef54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melb_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e572dc-328c-4089-b682-2d3a9d65a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. \n",
    "# We then take the average of those absolute errors. This is our measure of model quality.\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab2b80-53a1-4489-b8f8-b8840baf3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the prediction to a variable\n",
    "predicted_melb_model = melb_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f23b5-bb31-46f7-8a34-d37dae7e67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mean Absolute Error\n",
    "mean_absolute_error(y, predicted_melb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3295d2-32a6-48aa-b41c-14f10f7e343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since models' practical value come from making predictions on new data, we measure performance on data \n",
    "# that wasn't used to build the model. The most straightforward way to do this is to exclude some data from \n",
    "# the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. \n",
    "# This data is called validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544961f-cb9b-4013-9bd7-d1db7f5afbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scikit-learn library has a function train_test_split to break up the data into two pieces. \n",
    "# We'll use some of that data as training data to fit the model, and we'll use the other data as \n",
    "# validation data to calculate mean_absolute_error.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64edd4-fb8e-49f5-a02d-3e44b17b045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d4090-d36d-4844-9b05-4a72e6509683",
   "metadata": {},
   "outputs": [],
   "source": [
    "    melb_model2 = DecisionTreeRegressor(random_state=101)\n",
    "melb_model2.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2dc77-559a-46c7-9771-a65e9437808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = melb_model2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5649452-ae52-43a4-87f8-0c15f4702381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(test_y, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f834a5-35a0-4b22-a477-7a0d12aa196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a phenomenon called overfitting, where a model matches the training data almost perfectly, \n",
    "# but does poorly in validation and other new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323194f-03dc-4f18-9419-2b20d9ce3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  When a model fails to capture important distinctions and patterns in the data, so it performs poorly \n",
    "# even in training data, that is called underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe4d65-e791-4e0d-a04f-495f44e6c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, train_y, test_X, test_y):\n",
    "    model=DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=101)\n",
    "    model.fit(train_X, train_y)\n",
    "    test_predict=model.predict(test_X)\n",
    "    mae=mean_absolute_error(test_y, test_predict)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6d5e2-9872-4fc5-a2c7-18504b9a1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, train_y, test_X, test_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712c0b5-8282-4d12-9cdc-6ecd0af4cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the takeaway: Models can suffer from either:\n",
    "# Overfitting: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n",
    "# Underfitting: failing to capture relevant patterns, again leading to less accurate predictions.\n",
    "# We use validation data, which isn't used in model training, to measure a candidate model's accuracy. \n",
    "# This lets us try many candidate models and keep the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f8932-4805-4532-8512-c8ec62eba42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitted my participation in a House Prediction Competition Using Random Forest Regressor as my selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe45fc-c210-4cc4-b491-da793c883961",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Handling Overfitting and Underfitting\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a321ba9-5c30-4c8e-8295-b74c43577ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
